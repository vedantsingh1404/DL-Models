{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_cifar10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-IK3M0XFOMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hL7ZwZtvFcEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RL29b2oFkOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8df5b9e3-e318-4e78-d93b-be8d4b3b1781"
      },
      "source": [
        "train_data = torchvision.datasets.CIFAR10(root = './data', train = True, download = True, transform = transforms.ToTensor())\n",
        "test_data = torchvision.datasets.CIFAR10(root = './data', train = False, download = True, transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size = 50, shuffle = True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 50, shuffle = False)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsoRMWLLG0wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNN(nn.Module) :\n",
        "  def __init__ (self) :\n",
        "    super(ConvNN, self).__init__()\n",
        "    self.clayer1 = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size = 5, padding = 2, stride = 1),\n",
        "      nn.BatchNorm2d(16),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "    self.clayer2 = nn.Sequential(\n",
        "      nn.Conv2d(16, 32, kernel_size = 5, padding = 2, stride = 1),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "    self.dlayer = nn.Sequential(\n",
        "      nn.Linear(8 * 8 * 32, 512),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(p = 0.5),\n",
        "      nn.Linear(512, 128),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(p = 0.5),\n",
        "      nn.Linear(128, 10))\n",
        "  \n",
        "  def forward(self, x) :\n",
        "    x = self.clayer1(x)\n",
        "    x = self.clayer2(x)\n",
        "    x = x.reshape(x.size(0), -1)\n",
        "    x = self.dlayer(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wO075RNSIGQf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.0005\n",
        "max_epochs = 50\n",
        "# print(len(train_loader))\n",
        "# print(len(test_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhmAfhKCIdh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = ConvNN().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAQpytLCIWZC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(cnn.parameters(), lr = learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fquwRhWOKXWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82df8931-0801-4528-953f-c96b69acc7a6"
      },
      "source": [
        "for epoch in range(max_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        opt.zero_grad()\n",
        "        pred = cnn.forward(images)\n",
        "        loss = criterion(pred, labels)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        if (i + 1) % 500 == 0:\n",
        "          print('Epoch : {} / {}  |  Batch : {}  |  Loss : {:.3f}'.format(epoch + 1, max_epochs, i + 1, loss))\n",
        "          \n",
        "print(\"Finished Training\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1 / 50  |  Batch : 500  |  Loss : 1.433\n",
            "Epoch : 1 / 50  |  Batch : 1000  |  Loss : 1.649\n",
            "Epoch : 2 / 50  |  Batch : 500  |  Loss : 1.144\n",
            "Epoch : 2 / 50  |  Batch : 1000  |  Loss : 1.139\n",
            "Epoch : 3 / 50  |  Batch : 500  |  Loss : 1.171\n",
            "Epoch : 3 / 50  |  Batch : 1000  |  Loss : 0.870\n",
            "Epoch : 4 / 50  |  Batch : 500  |  Loss : 1.131\n",
            "Epoch : 4 / 50  |  Batch : 1000  |  Loss : 1.113\n",
            "Epoch : 5 / 50  |  Batch : 500  |  Loss : 1.014\n",
            "Epoch : 5 / 50  |  Batch : 1000  |  Loss : 1.073\n",
            "Epoch : 6 / 50  |  Batch : 500  |  Loss : 0.659\n",
            "Epoch : 6 / 50  |  Batch : 1000  |  Loss : 0.689\n",
            "Epoch : 7 / 50  |  Batch : 500  |  Loss : 0.955\n",
            "Epoch : 7 / 50  |  Batch : 1000  |  Loss : 0.671\n",
            "Epoch : 8 / 50  |  Batch : 500  |  Loss : 0.961\n",
            "Epoch : 8 / 50  |  Batch : 1000  |  Loss : 1.011\n",
            "Epoch : 9 / 50  |  Batch : 500  |  Loss : 0.718\n",
            "Epoch : 9 / 50  |  Batch : 1000  |  Loss : 1.211\n",
            "Epoch : 10 / 50  |  Batch : 500  |  Loss : 0.542\n",
            "Epoch : 10 / 50  |  Batch : 1000  |  Loss : 0.913\n",
            "Epoch : 11 / 50  |  Batch : 500  |  Loss : 0.884\n",
            "Epoch : 11 / 50  |  Batch : 1000  |  Loss : 0.611\n",
            "Epoch : 12 / 50  |  Batch : 500  |  Loss : 0.698\n",
            "Epoch : 12 / 50  |  Batch : 1000  |  Loss : 0.987\n",
            "Epoch : 13 / 50  |  Batch : 500  |  Loss : 0.789\n",
            "Epoch : 13 / 50  |  Batch : 1000  |  Loss : 0.556\n",
            "Epoch : 14 / 50  |  Batch : 500  |  Loss : 0.473\n",
            "Epoch : 14 / 50  |  Batch : 1000  |  Loss : 0.710\n",
            "Epoch : 15 / 50  |  Batch : 500  |  Loss : 0.666\n",
            "Epoch : 15 / 50  |  Batch : 1000  |  Loss : 0.614\n",
            "Epoch : 16 / 50  |  Batch : 500  |  Loss : 0.594\n",
            "Epoch : 16 / 50  |  Batch : 1000  |  Loss : 0.531\n",
            "Epoch : 17 / 50  |  Batch : 500  |  Loss : 0.730\n",
            "Epoch : 17 / 50  |  Batch : 1000  |  Loss : 0.682\n",
            "Epoch : 18 / 50  |  Batch : 500  |  Loss : 0.825\n",
            "Epoch : 18 / 50  |  Batch : 1000  |  Loss : 0.787\n",
            "Epoch : 19 / 50  |  Batch : 500  |  Loss : 0.595\n",
            "Epoch : 19 / 50  |  Batch : 1000  |  Loss : 0.569\n",
            "Epoch : 20 / 50  |  Batch : 500  |  Loss : 0.480\n",
            "Epoch : 20 / 50  |  Batch : 1000  |  Loss : 0.421\n",
            "Epoch : 21 / 50  |  Batch : 500  |  Loss : 0.268\n",
            "Epoch : 21 / 50  |  Batch : 1000  |  Loss : 0.751\n",
            "Epoch : 22 / 50  |  Batch : 500  |  Loss : 0.744\n",
            "Epoch : 22 / 50  |  Batch : 1000  |  Loss : 0.540\n",
            "Epoch : 23 / 50  |  Batch : 500  |  Loss : 0.332\n",
            "Epoch : 23 / 50  |  Batch : 1000  |  Loss : 0.289\n",
            "Epoch : 24 / 50  |  Batch : 500  |  Loss : 0.211\n",
            "Epoch : 24 / 50  |  Batch : 1000  |  Loss : 0.553\n",
            "Epoch : 25 / 50  |  Batch : 500  |  Loss : 0.341\n",
            "Epoch : 25 / 50  |  Batch : 1000  |  Loss : 0.605\n",
            "Epoch : 26 / 50  |  Batch : 500  |  Loss : 0.263\n",
            "Epoch : 26 / 50  |  Batch : 1000  |  Loss : 0.352\n",
            "Epoch : 27 / 50  |  Batch : 500  |  Loss : 0.246\n",
            "Epoch : 27 / 50  |  Batch : 1000  |  Loss : 0.586\n",
            "Epoch : 28 / 50  |  Batch : 500  |  Loss : 0.271\n",
            "Epoch : 28 / 50  |  Batch : 1000  |  Loss : 0.426\n",
            "Epoch : 29 / 50  |  Batch : 500  |  Loss : 0.307\n",
            "Epoch : 29 / 50  |  Batch : 1000  |  Loss : 0.357\n",
            "Epoch : 30 / 50  |  Batch : 500  |  Loss : 0.421\n",
            "Epoch : 30 / 50  |  Batch : 1000  |  Loss : 0.241\n",
            "Epoch : 31 / 50  |  Batch : 500  |  Loss : 0.355\n",
            "Epoch : 31 / 50  |  Batch : 1000  |  Loss : 0.290\n",
            "Epoch : 32 / 50  |  Batch : 500  |  Loss : 0.349\n",
            "Epoch : 32 / 50  |  Batch : 1000  |  Loss : 0.284\n",
            "Epoch : 33 / 50  |  Batch : 500  |  Loss : 0.191\n",
            "Epoch : 33 / 50  |  Batch : 1000  |  Loss : 0.274\n",
            "Epoch : 34 / 50  |  Batch : 500  |  Loss : 0.228\n",
            "Epoch : 34 / 50  |  Batch : 1000  |  Loss : 0.377\n",
            "Epoch : 35 / 50  |  Batch : 500  |  Loss : 0.333\n",
            "Epoch : 35 / 50  |  Batch : 1000  |  Loss : 0.507\n",
            "Epoch : 36 / 50  |  Batch : 500  |  Loss : 0.128\n",
            "Epoch : 36 / 50  |  Batch : 1000  |  Loss : 0.513\n",
            "Epoch : 37 / 50  |  Batch : 500  |  Loss : 0.373\n",
            "Epoch : 37 / 50  |  Batch : 1000  |  Loss : 0.601\n",
            "Epoch : 38 / 50  |  Batch : 500  |  Loss : 0.272\n",
            "Epoch : 38 / 50  |  Batch : 1000  |  Loss : 0.488\n",
            "Epoch : 39 / 50  |  Batch : 500  |  Loss : 0.330\n",
            "Epoch : 39 / 50  |  Batch : 1000  |  Loss : 0.291\n",
            "Epoch : 40 / 50  |  Batch : 500  |  Loss : 0.337\n",
            "Epoch : 40 / 50  |  Batch : 1000  |  Loss : 0.340\n",
            "Epoch : 41 / 50  |  Batch : 500  |  Loss : 0.234\n",
            "Epoch : 41 / 50  |  Batch : 1000  |  Loss : 0.254\n",
            "Epoch : 42 / 50  |  Batch : 500  |  Loss : 0.289\n",
            "Epoch : 42 / 50  |  Batch : 1000  |  Loss : 0.350\n",
            "Epoch : 43 / 50  |  Batch : 500  |  Loss : 0.214\n",
            "Epoch : 43 / 50  |  Batch : 1000  |  Loss : 0.269\n",
            "Epoch : 44 / 50  |  Batch : 500  |  Loss : 0.517\n",
            "Epoch : 44 / 50  |  Batch : 1000  |  Loss : 0.409\n",
            "Epoch : 45 / 50  |  Batch : 500  |  Loss : 0.115\n",
            "Epoch : 45 / 50  |  Batch : 1000  |  Loss : 0.342\n",
            "Epoch : 46 / 50  |  Batch : 500  |  Loss : 0.163\n",
            "Epoch : 46 / 50  |  Batch : 1000  |  Loss : 0.409\n",
            "Epoch : 47 / 50  |  Batch : 500  |  Loss : 0.180\n",
            "Epoch : 47 / 50  |  Batch : 1000  |  Loss : 0.209\n",
            "Epoch : 48 / 50  |  Batch : 500  |  Loss : 0.113\n",
            "Epoch : 48 / 50  |  Batch : 1000  |  Loss : 0.138\n",
            "Epoch : 49 / 50  |  Batch : 500  |  Loss : 0.258\n",
            "Epoch : 49 / 50  |  Batch : 1000  |  Loss : 0.337\n",
            "Epoch : 50 / 50  |  Batch : 500  |  Loss : 0.123\n",
            "Epoch : 50 / 50  |  Batch : 1000  |  Loss : 0.226\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lc3abYInJOsP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e4826c49-a8d7-46cc-c241-efb60f7dbbab"
      },
      "source": [
        "cnn.eval()\n",
        "with torch.no_grad() :\n",
        "  \n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  for images, labels in test_loader :\n",
        "    images = images.to('cuda')\n",
        "    labels = labels.to('cuda')\n",
        "    \n",
        "    out = cnn.forward(images)\n",
        "    \n",
        "    pred = torch.argmax(out.data, 1)\n",
        "    \n",
        "    total += labels.size(0)\n",
        "    correct += (pred == labels).sum().item()\n",
        "  print(correct)\n",
        "  print(total)\n",
        "  print(100 * correct / total)\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7496\n",
            "10000\n",
            "74.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pQltQAKJk4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ec145645-dd39-4095-d60b-782cd2f6360a"
      },
      "source": [
        "cnn.eval()\n",
        "with torch.no_grad() :\n",
        "  \n",
        "  correct = 0\n",
        "  total = 0\n",
        "  \n",
        "  for images, labels in train_loader :\n",
        "    images = images.to('cuda')\n",
        "    labels = labels.to('cuda')\n",
        "    \n",
        "    out = cnn.forward(images)\n",
        "    \n",
        "    pred = torch.argmax(out.data, 1)\n",
        "    \n",
        "    total += labels.size(0)\n",
        "    correct += (pred == labels).sum().item()\n",
        "  print(correct)\n",
        "  print(total)\n",
        "  print(100 * correct / total)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49465\n",
            "50000\n",
            "98.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uV5HG971PLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}